{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übung zur Sentimentanalyse - Analyse von Twitter Daten\n",
    "\n",
    "## Aufgabe 1: Theorie\n",
    "\n",
    "### 1.1 Wozu dient das Package TextBlob von Python und wie wird es angewendet?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Wie muss der Text vorbereitet werden, um den TextBlob Classifier anwenden  zu können?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2: Übung Twitter-Data-Mining\n",
    "### In dieser Übung sollen alle Tweets mit dem Tag \"dataScience\" über die Twitter API gesammelt werden.\n",
    "Für die folgende Übung wird zunächst ein API Key von Twitter benötigt.\n",
    "Diesen bekommt man unter [apps.twitter.com](https://apps.twitter.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Die Zugangsdaten sollen in einem Python Modul *credentials.py* , welches im selben Ordner liegen sein muss, abgespeichert werden:\n",
    "\n",
    "Dieses könnte folgendermaßen aussehen.\n",
    "```python\n",
    "# Consume:\n",
    "CONSUMER_KEY    = ''\n",
    "CONSUMER_SECRET = ''\n",
    "\n",
    "# Access:\n",
    "ACCESS_TOKEN  = ''\n",
    "ACCESS_SECRET = ''\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Anschließend werden Imports für folgenden Packages benötigt\n",
    "* tweepy\n",
    "* pandas\n",
    "* numpy\n",
    "* credentials\n",
    "* TextBlob\n",
    "* re\n",
    "\n",
    "Für die Visualisierung benötigen wir zusätzlich\n",
    "* matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 API Setup und Authentication mit Hilfe des API Keys\n",
    "Hier sollen nun mit Hilfe des credentials Modules die Authentication und somit die API Verbindung hergestellt werden.<br>\n",
    "Hilfe beim Setup bietet unter anderem dieses [Tutorial](https://www.sitepoint.com/how-to-create-a-twitter-app-and-api-interface-via-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Erstellen eines Objektes, über welches Twitter-Abfragen getätigt werden können\n",
    "Die Methode um nach einfachen Tags zu suchen lautet: \n",
    "``` python\n",
    "search(q= \"SearchTag\")\n",
    "```\n",
    "Anschließend sollen die gesammelten Tweets ausgegeben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Speichern der Tweets in einem Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Um den Aufbau der Tweets einzusehen, werden folgende Attribute des 1. Tweets ausgeben:\n",
    "* id\n",
    "* created_at\n",
    "* source\n",
    "* favorite_count\n",
    "* retweet_count\n",
    "* geo\n",
    "* coordinates\n",
    "* entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Dem Dataframe werden folgende Attribute hinzugefügt:\n",
    "* Länge des Textes (len)\n",
    "* ID\n",
    "* created_at\n",
    "* source\n",
    "* favorite_count\n",
    "* retweet_count \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Wie lang sind die  gesammelten Tweets durchschnittlich? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 Welcher Tweet hat die meisten Likes bekommen? Welcher Tweet wurde am häufigsten retweetet?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10 Um die Daten über Zeit zu analysieren, wird eine ein Objekt der Klasse *Series* aus dem Package Pandas, für die Attribute *len*, *favorite_count* und *retweet_count* mit dem Attribut *created_at* als Index erstellt.\n",
    "\n",
    "Dies lässt sich  mit Hilfe der pandas Methode \n",
    "```python\n",
    "pd.series(data,index)\n",
    "```\n",
    "realisieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.11 Plot der Länge der Tweets über Zeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.13 Über welche Tools (Sources) wurde getwittert? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.14 Um die eigentliche Sentimentanalyse durchführen zu können, müssen die Texte vorab \"gecleaned\" werden\n",
    "Zuerst müssen die Tweets gecleaned werden.<br>Das bedeutet wir entfernen folgende Sonderzeichen:\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \"<br> Hierbei hilft das Package **re**. <!--- Wird beim bereinigen der Sonderzeichen auch ein Komma ohne Leerzeichen berücksichtigt? ---> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.15 Anschließends kann der TextBlob Classifier verwendet werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.16 Die Ergebnisse werden in einer zusätzlichen Spalte (z.B. \"Sentiment\") im Dataframe dargestellt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.17 Die Sentimente werden in Prozentangaben ausgeben\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
